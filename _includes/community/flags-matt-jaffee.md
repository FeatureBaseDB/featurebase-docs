

## Common Flags
  -b, --batch-size int   Number of records to read before indexing all of them at once. Generally, larger means better throughput and more memory usage. 1,048,576 might be a good number. (default 1)
  -c, --concurrency int  Number of concurrent sources and indexing routines to launch. Concurrency is not supported for molecula-consumer-sql. Concurrency for molecula-consumer-csv only works when providing multiple files and does not support '--auto-generate' (default 1)
--featurebase-hosts strings    Comma separated list of host:port pairs for FeatureBase. (default [])
--index string     Name of FeatureBase index.
--use-shard-transactional-endpoint   Use alternate import endpoint that ingests data for all fields in a shard in a single atomic request. No negative performance impact and better consistency. Recommended.

## These are in com-ingest-flag-common-id

--id-field string  Field which contains the integer column ID. May not be used in conjunction with primary-key-fields. If both are empty, auto-generated IDs will be used.
--primary-key-fields strings   Data field(s) which make up the primary key for a record. These will be concatenated and translated to a FeatureBase ID. If empty, record key translation will not be used. (default [])

## Generate ID Flags
--auto-generate    Automatically generate IDs.
--external-generate  Use FeatureBase's ID generation (must be set alongside auto-generate).
--id-alloc-key-prefix string   A prefix for ID allocator keys when using FeatureBase's ID generation (must be different for each concurrent ingester). (default "ingest")
--offset-mode Set offset-mode based Autogenerated IDs, for use with a data-source that is offset-based (must be set alongside auto-generate and external-generate).

## CSV Specific? TODO: verify this is true
--files strings    List of files, URLs, or directories to ingest. (default [])
--ignore-header    Ignore header in file and use configured header. You *must* configure a header.
--header strings   Optional header. If not passed, first line of each file is used. (default [])

## SQL specific
--driver string    key used for finding go sql database driver (default "postgres")
--connection-string string     credentials for connecting to sql database (default "postgres://user:password@localhost:5432/defaultindex?sslmode=disable")
--row-expr string  sql + type description on input
--string-array-separator stringseparator used to delineate values in string array (default ",")

## Kafka Specific

--header string  Path to the static schema, in JSON header format. May be a path on the local filesystem, or an S3 URI (requires setting --s3-region or environment variable AWS_REGION).
--kafka-tls.*
--group
--skip-old
--timeout
--topics
--kafka*

## Kafka Delete Specific
--featurebase-grpc-hosts strings     Comma separated list of host:port pairs for FeatureBase's GRPC endpoint. Used by Kafka delete consumer. (default [])

## Error Handling Flags
--allow-decimal-out-of-range   Allow ingest to continue when it encounters out of range decimals in DecimalFields. (default false)
--allow-int-out-of-range Allow ingest to continue when it encounters out of range integers in IntFields. (default false)
--allow-timestamp-out-of-range Allow ingest to continue when it encounters out of range timestamps in TimestampFields. (default false)
--batch-max-staleness duration Maximum length of time that the oldest record in a batch can exist before flushing the batch. Note that this can potentially stack with timeouts waiting for the source.
--commit-timeout duration Maximum time before canceling commit. "Commit" here refers to the process of telling the data source that the current batch of records is fully ingested. For a kafka data source this is well-defined, whereas for others such as the CSV ingester it may do nothing.
--skip-bad-rows intIf you fail to process the first n rows without processing one successfully, fail.

## Authentication Flags
--auth-token stringAuthentication Token for FeatureBase
--tls.ca-certificate string    Path to CA certificate file, or literal PEM data.
--tls.certificate string Path to certificate file, or literal PEM data.
--tls.enable-client-verification     Enable verification of client certificates.
--tls.key string   Path to certificate key file, or literal PEM data.
--tls.skip-verify  Disables verification of server certificates.

## Logging & statistics flags
--log-path string  Log file to write to. Empty means stderr.
--pprof string     host:port on which to listen for pprof (default "localhost:6062")
--stats string     host:port on which to host metrics (default "localhost:9093")
--track-progress   Periodically print status updates on how many records have been sourced.
--verbose    Enable verbose logging.
--write-csv string Write data we're ingesting to a CSV file with the given name.

## Testing Flags
--delete-index     Delete index specified by --index (if it already exists) before starting ingest - NOTE: this will delete any data already imported into this index, use with caution.
--dry-run    Dry run - just flag parsing.
--max-msgs uint    Number of messages to consume from Kafka before stopping. Useful for testing when you don't want to run indefinitely.

##  Flags you probably shouldn't use
--cache-length uintNumber of batches of ID mappings to cache. (default 64)
--key-translate-batch-size int Maximum number of keys to translate at a time.
--lookup-batch-size int  Number of records to batch before writing them to Lookup database.
--lookup-db-dsn string   Connection string for connecting to Lookup database.
  -j, --just-do-it Any header field not in the appropriate format, just downcase, use it as the name and process the value as a String/set field

# Flags to discard or which are being reviewed

## Discard

Discard (don't document these, I'll make eng tickets to get rid of them

Found in com-ingest-flag-not-used.md

--assume-empty-featurebase     Setting this means that you're doing an initial bulk ingest which assumes that data does not need to be cleared/unset in FeatureBase. There are various performance enhancements that can be made in this case. For example, for booleans if a false value comes in, we'll just set the bit in the bools-exists field... we won't clear it in the bools field.
--assume-empty-pilosa    Alias for --assume-empty-featurebase. Will be deprecated in the next major release.
--exp-split-batch-mode   Tell featurebase client to build bitmaps locally over many batches and import them at the end. Experimental. Does not support int or mutex fields. Don't use this unless you know what you're doing.
--pilosa-hosts strings   Alias for --featurebase-hosts. Will be deprecated in the next major release. (default [localhost:10101])
--pilosa-grpc-hosts strings    Alias for --featurebase-grpc-hosts. Will be deprecated in the next major release. (default [localhost:20101])

## Engineering Revist
--future.rename    Interact with FeatureBase instead of Pilosa.
  -k, --pack-bools stringIf non-empty, boolean fields will be packed into two set fieldsâ€”one with this name, and one with <name>-exists. (default "bools")

## Cloud/Serverless specific flags

(We can mention these, but don't need to explain them).
These are experimental and only used internally to the cloud product, feel free to ignore them.

--mds-address string     MDS address.
--table-name stringhuman friendly table name
--database-id string     auto-assigned database ID
--organization-id string auto-assigned organization ID
